{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding is a type of mapping that allows words with similar meaning to have similar representation. Word2vec is a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words. There are two types of Word2vec: Skip gram, Continous Bag of Words(CBOW).\n",
    "\n",
    "Skip gram passes a one-hot vector of size equal to vocabulary of natural corpora into a shallow 2 layer neural network. It contains a hidden layer of n dimensions where n is less than the vocabulary size. Finally k one-hot vectors are generated as output after softmax which represent the probabaility distribution over each word. Here k equals the window size. The hidden layer is the vector representation of the word.\n",
    "\n",
    "CBOW swaps the input and output of a skip gram model. For generating the vector representation, all the examples of the target word are passed as input and averaged. \n",
    "\n",
    "Skip gram and CBOW work almost similarly with skip gram performing slightly better in case of rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that bummer you shoulda got david carr of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it not behaving at all mad why am here beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that bummer you shoulda got david carr of...       0\n",
       "1  is upset that he can not update his facebook b...       0\n",
       "2  dived many times for the ball managed to save ...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it not behaving at all mad why am here beca...       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = 'df.csv'\n",
    "df = pd.read_csv(csv, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1596036</th>\n",
       "      <td>just woke up having no school is the best feel...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596037</th>\n",
       "      <td>thewdb com very cool to hear old walt interviews</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596038</th>\n",
       "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596039</th>\n",
       "      <td>happy th birthday to my boo of alll time tupac...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596040</th>\n",
       "      <td>happy charitytuesday</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  target\n",
       "1596036  just woke up having no school is the best feel...       4\n",
       "1596037   thewdb com very cool to hear old walt interviews       4\n",
       "1596038  are you ready for your mojo makeover ask me fo...       4\n",
       "1596039  happy th birthday to my boo of alll time tupac...       4\n",
       "1596040                               happy charitytuesday       4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.target == 4, 'target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1596036</th>\n",
       "      <td>just woke up having no school is the best feel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596037</th>\n",
       "      <td>thewdb com very cool to hear old walt interviews</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596038</th>\n",
       "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596039</th>\n",
       "      <td>happy th birthday to my boo of alll time tupac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596040</th>\n",
       "      <td>happy charitytuesday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  target\n",
       "1596036  just woke up having no school is the best feel...       1\n",
       "1596037   thewdb com very cool to hear old walt interviews       1\n",
       "1596038  are you ready for your mojo makeover ask me fo...       1\n",
       "1596039  happy th birthday to my boo of alll time tupac...       1\n",
       "1596040                               happy charitytuesday       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has total 1564120 entries with 50.02% negative, 49.98% positive\n",
      "Validation set has total 15960 entries with 49.45% negative, 50.55% positive\n",
      "Test set has total 15961 entries with 49.68% negative, 50.32% positive\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x = df.text\n",
    "y = df.target\n",
    "SEED = 2000\n",
    "\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)\n",
    "print(\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_train), (len(x_train[y_train == 0]) / (len(x_train)*1.))*100, (len(x_train[y_train == 1]) / (len(x_train)*1.))*100))\n",
    "print(\"Validation set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_validation), (len(x_validation[y_validation == 0]) / (len(x_validation)*1.))*100, (len(x_validation[y_validation == 1]) / (len(x_validation)*1.))*100))\n",
    "print(\"Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_test), (len(x_test[y_test == 0]) / (len(x_test)*1.))*100, (len(x_test[y_test == 1]) / (len(x_test)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that bummer you shoulda got david carr of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it not behaving at all mad why am here beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that bummer you shoulda got david carr of...       0\n",
       "1  is upset that he can not update his facebook b...       0\n",
       "2  dived many times for the ball managed to save ...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it not behaving at all mad why am here beca...       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286274    signed up for stumbleupon because uses it if s...\n",
       "50691                         aww can not join need to study\n",
       "1271252                         why do you dance really good\n",
       "634177     hope get to sleep in tomorrow working in my da...\n",
       "413732     just biked home froze my ass off but got good ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_x = pd.concat([x_train, x_validation, x_test])\n",
    "all_x.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.23) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm # makes the loops show a smart progress meter\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec # open source vector space modelling and topic modelling toolkit in python \n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "import multiprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "def labelize_tweets_ug(tweets, label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(LabeledSentence(t.split(), [prefix + '_%s' % i]))\n",
    "    return result\n",
    "  \n",
    "all_x_w2v = labelize_tweets_ug(all_x, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2188582.63it/s]\n",
      "100%|██████████| 1596041/1596041 [00:01<00:00, 1294546.74it/s]\n",
      "100%|██████████| 1596041/1596041 [00:01<00:00, 1294820.67it/s]\n",
      "100%|██████████| 1596041/1596041 [00:01<00:00, 1324005.13it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2195970.18it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2191790.71it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 1913173.78it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2194809.58it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2194382.22it/s]\n",
      "100%|██████████| 1596041/1596041 [00:01<00:00, 1407547.06it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2206682.78it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2207229.20it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2211783.46it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2194303.82it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2193724.96it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2199621.98it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2214512.60it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2195159.36it/s]\n",
      "100%|██████████| 1596041/1596041 [00:01<00:00, 1405893.45it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2197592.91it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2190781.48it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2197095.96it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2205600.93it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2193951.43it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2194021.18it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2208895.58it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 1891566.73it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2186128.29it/s]\n",
      "100%|██████████| 1596041/1596041 [00:01<00:00, 1576366.78it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2201790.22it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2195391.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7407894736842106"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distributed Bag Of Words (DBOW)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_dbow = Doc2Vec(dm=0, size=100, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dbow.build_vocab([x for x in tqdm(all_x_w2v)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_ug_dbow.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_dbow.alpha -= 0.002\n",
    "    model_ug_dbow.min_alpha = model_ug_dbow.alpha\n",
    "    \n",
    "def get_vectors(model, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = model.docvecs[prefix]\n",
    "        n += 1\n",
    "    return vecs\n",
    "  \n",
    "train_vecs_dbow = get_vectors(model_ug_dbow, x_train, 100)\n",
    "validation_vecs_dbow = get_vectors(model_ug_dbow, x_validation, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow, y_train)\n",
    "clf.score(validation_vecs_dbow, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2113690.27it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2186402.46it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2193402.23it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2192162.50it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2185535.18it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2183696.54it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2193969.41it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2193750.12it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2214622.49it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2190714.09it/s]\n",
      "100%|██████████| 1596041/1596041 [00:01<00:00, 1383265.98it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2191772.77it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2088941.08it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2185190.60it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2194223.26it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2190548.49it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2212607.35it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2211853.62it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2197723.50it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2207770.06it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2200685.67it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2196181.99it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2191549.61it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2194139.84it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2209140.50it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2195530.13it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2197011.60it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2196225.22it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 1904932.43it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2210715.59it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2194852.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.668984962406015"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distributed Memory Concatenation (DMC)\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_dmc = Doc2Vec(dm=1, dm_concat=1, size=100, window=2, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dmc.build_vocab([x for x in tqdm(all_x_w2v)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_ug_dmc.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_dmc.alpha -= 0.002\n",
    "    model_ug_dmc.min_alpha = model_ug_dmc.alpha\n",
    "   \n",
    "train_vecs_dmc = get_vectors(model_ug_dmc, x_train, 100)\n",
    "validation_vecs_dmc = get_vectors(model_ug_dmc, x_validation, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmc, y_train)\n",
    "clf.score(validation_vecs_dmc, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2145670.33it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2202716.11it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2201510.72it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2201828.60it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2190371.46it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2206384.59it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2214341.19it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2217681.86it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2218063.95it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2213027.94it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2216621.50it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2211573.02it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2219174.99it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2217457.07it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2206332.95it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2222379.74it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2220152.38it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2220044.88it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2220534.59it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2214408.58it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2215175.78it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2214824.72it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2205484.67it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2218757.94it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2213195.48it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2220269.46it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2223859.26it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2222817.34it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2217363.79it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2213975.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7335839598997493"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distributed Memory Mean (DMM)\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_dmm = Doc2Vec(dm=1, dm_concat=0, size=100, window=2, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dmm.build_vocab([x for x in tqdm(all_x_w2v)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_ug_dmm.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_dmm.alpha -= 0.002\n",
    "    model_ug_dmm.min_alpha = model_ug_dmm.alpha\n",
    "    \n",
    "train_vecs_dmm = get_vectors(model_ug_dmm, x_train, 100)\n",
    "validation_vecs_dmm = get_vectors(model_ug_dmm, x_validation, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmm, y_train)\n",
    "clf.score(validation_vecs_dmm, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7472431077694236"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distributed Bag Of Words (DBOW) + Distributed Memory Concatenation (DMC)\n",
    "\n",
    "def get_concat_vectors(model1,model2, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = np.append(model1.docvecs[prefix], model2.docvecs[prefix])\n",
    "        n += 1\n",
    "    return vecs\n",
    "\n",
    "train_vecs_dbow_dmc = get_concat_vectors(model_ug_dbow, model_ug_dmc, x_train, 200)\n",
    "validation_vecs_dbow_dmc = get_concat_vectors(model_ug_dbow, model_ug_dmc, x_validation, 200)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_dmc, y_train)\n",
    "clf.score(validation_vecs_dbow_dmc, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7548872180451128"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distributed Bag Of Words (DBOW) + Distributed Memory Mean (DMM)\n",
    "\n",
    "train_vecs_dbow_dmm = get_concat_vectors(model_ug_dbow, model_ug_dmm, x_train, 200)\n",
    "validation_vecs_dbow_dmm = get_concat_vectors(model_ug_dbow, model_ug_dmm, x_validation, 200)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_dmm, y_train)\n",
    "clf.score(validation_vecs_dbow_dmm, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrase Modelling\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "tokenized_train = [t.split() for t in x_train]\n",
    "phrases = Phrases(tokenized_train)\n",
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['your', 'not', 'pregnant', 'oh', 'no', 'what', 'shame']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 288048,  357753,  420123,  348643, 1195630,  424869,  675535,\n",
       "             475529,  682421,  434584,\n",
       "            ...\n",
       "            1010148, 1070094, 1278135,  223204, 1521275,  689718,  856013,\n",
       "             324814,  430920,  879542],\n",
       "           dtype='int64', length=1564120)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288048                    your not pregnant oh no what shame\n",
       "357753                                 cleaning the bathroom\n",
       "420123     feeling left out you never recommend anything ...\n",
       "348643     home sick what the hell wonder if it ll mutate...\n",
       "1195630        your tweet reminded me that game was the shit\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'body of missing northern calif girl found police have found the remains of missing northern california girl'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body',\n",
       " 'of',\n",
       " 'missing',\n",
       " 'northern',\n",
       " 'calif',\n",
       " 'girl',\n",
       " 'found',\n",
       " 'police',\n",
       " 'have',\n",
       " 'found',\n",
       " 'the',\n",
       " 'remains',\n",
       " 'of',\n",
       " 'missing',\n",
       " 'northern_california',\n",
       " 'girl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram[x_train[100].split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def labelize_tweets_bg(tweets, label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(LabeledSentence(bigram[t.split()], [prefix + '_%s' % i]))\n",
    "    return result\n",
    "  \n",
    "all_x = pd.concat([x_train, x_validation, x_test])\n",
    "all_x_w2v_bg = labelize_tweets_bg(all_x, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2199820.04it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2205556.61it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2210389.30it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2202511.02it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2206002.87it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2216660.40it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2209661.88it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2209222.89it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2216025.67it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 1985959.18it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2218683.67it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2215782.15it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2205834.95it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2217502.61it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2220043.41it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2221597.96it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2217800.88it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2223151.00it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2214829.12it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2215257.88it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2217007.63it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2216845.38it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2202148.75it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2190549.93it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2218442.51it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2215331.19it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2215057.77it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2203414.31it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2210682.74it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2217463.68it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2211250.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7402255639097745"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DBOW with bigram\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dbow = Doc2Vec(dm=0, size=100, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_bg_dbow.build_vocab([x for x in tqdm(all_x_w2v_bg)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_bg_dbow.train(utils.shuffle([x for x in tqdm(all_x_w2v_bg)]), total_examples=len(all_x_w2v_bg), epochs=1)\n",
    "    model_bg_dbow.alpha -= 0.002\n",
    "    model_bg_dbow.min_alpha = model_bg_dbow.alpha\n",
    "    \n",
    "train_vecs_dbow_bg = get_vectors(model_bg_dbow, x_train, 100)\n",
    "validation_vecs_dbow_bg = get_vectors(model_bg_dbow, x_validation, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_bg, y_train)\n",
    "clf.score(validation_vecs_dbow_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2153388.26it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2207608.43it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2196827.75it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2199979.81it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2211301.26it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2191323.64it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2195309.09it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2216562.05it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2215155.26it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2216526.08it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2211411.56it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2213968.43it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2214743.39it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2213404.77it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2214983.02it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2212287.81it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2214054.84it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2214955.17it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2217957.39it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2213087.93it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2210314.13it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2211269.12it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2212614.66it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2206220.98it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2216931.28it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2206700.97it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2217152.28it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2215232.96it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2214232.06it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2211909.16it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2218228.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6622180451127819"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DMC with bigram\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dmc = Doc2Vec(dm=1, dm_concat=1, size=100, window=2, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_bg_dmc.build_vocab([x for x in tqdm(all_x_w2v_bg)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_bg_dmc.train(utils.shuffle([x for x in tqdm(all_x_w2v_bg)]), total_examples=len(all_x_w2v_bg), epochs=1)\n",
    "    model_bg_dmc.alpha -= 0.002\n",
    "    model_bg_dmc.min_alpha = model_bg_dmc.alpha\n",
    "    \n",
    "train_vecs_dmc_bg = get_vectors(model_bg_dmc, x_train, 100)\n",
    "validation_vecs_dmc_bg = get_vectors(model_bg_dmc, x_validation, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmc_bg, y_train)\n",
    "clf.score(validation_vecs_dmc_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2209602.07it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2198186.08it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2210006.20it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2209213.41it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2205611.11it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2207947.01it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2205170.82it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2210834.60it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2212211.78it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2210758.67it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2218838.84it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2212501.31it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2214090.72it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2220308.49it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2222181.29it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2216195.87it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2214637.88it/s]\n",
      "100%|██████████| 1596041/1596041 [00:00<00:00, 2207373.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-76a30b6d25c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel_bg_dmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_x_w2v_bg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_x_w2v_bg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmodel_bg_dmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m0.002\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel_bg_dmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_bg_dmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, documents, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raw_word_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m             trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[1;32m    256\u001b[0m                 \u001b[0mdata_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                 queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[1;32m    258\u001b[0m             \u001b[0mtrained_word_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrained_word_count_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mraw_word_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mraw_word_count_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    225\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m    226\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             report_delay=report_delay)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DMM with bigram\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dmm = Doc2Vec(dm=1, dm_mean=1, size=100, window=4, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_bg_dmm.build_vocab([x for x in tqdm(all_x_w2v_bg)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_bg_dmm.train(utils.shuffle([x for x in tqdm(all_x_w2v_bg)]), total_examples=len(all_x_w2v_bg), epochs=1)\n",
    "    model_bg_dmm.alpha -= 0.002\n",
    "    model_bg_dmm.min_alpha = model_bg_dmm.alpha\n",
    "    \n",
    "train_vecs_dmm_bg = get_vectors(model_bg_dmm, x_train, 100)\n",
    "validation_vecs_dmm_bg = get_vectors(model_bg_dmm, x_validation, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmm_bg, y_train)\n",
    "clf.score(validation_vecs_dmm_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigram\n",
    "\n",
    "tg_phrases = Phrases(bigram[tokenized_train])\n",
    "trigram = Phraser(tg_phrases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
